{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the definitive version for producing CMIP5 time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xy\n",
    "import string\n",
    "from copy import deepcopy\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileInfo(dataDir,fileNameSplitter='_',fileNamePos=2):\n",
    "    def justDataFiles(path=None):\n",
    "        for f in os.listdir(path):\n",
    "            if ('p1_21' not in f) and ('p1_22' not in f) and ('.nc' in f):\n",
    "                yield f\n",
    "            \n",
    "    files = [x for x in justDataFiles(dataDir)]  \n",
    "    files.sort()\n",
    "    \n",
    "    #make a list of the model names in this file list\n",
    "    modelNames = []\n",
    "    for oneFile in files:\n",
    "        justFileName = str.split(oneFile,'/')[-1]\n",
    "        #print justFileName\n",
    "        justEnsMemNum = str.split(justFileName,fileNameSplitter)[fileNamePos]\n",
    "        #print justEnsMemNum\n",
    "        modelNames.append(justEnsMemNum)\n",
    "    modelNames = list(set(modelNames))\n",
    "\n",
    "    #make a dictionary of all the files that go with each model\n",
    "    keyvaluepairs = []\n",
    "    for model in modelNames:\n",
    "        uniqueModelName = ''.join([model,fileNameSplitter])\n",
    "        oneModelFileList = []\n",
    "        for oneFile in files:\n",
    "            if uniqueModelName in oneFile:\n",
    "                oneModelFileList.append(oneFile)\n",
    "        tupleOfKeyValue = (model,oneModelFileList)\n",
    "        keyvaluepairs.append(tupleOfKeyValue)\n",
    "\n",
    "    fileDict = dict(keyvaluepairs)\n",
    "    \n",
    "    return fileDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAreaAvg(data,bounds,weights): #,t,weights):\n",
    "\n",
    "    weightedMean = 0.0\n",
    "    weightTotal = 0.0\n",
    "    \n",
    "    areaSubset = data.sel(lon=slice(bounds.lonMin,bounds.lonMax),lat=slice(bounds.latMin,bounds.latMax)) #.isel(time=t)\n",
    "    \n",
    "    useCosLat = False\n",
    "    if weights is None:\n",
    "        useCosLat = True\n",
    "    else:\n",
    "        try:\n",
    "            if len(weights.dims)==2:\n",
    "                weightsSubset = weights.sel(lon=slice(bounds.lonMin,bounds.lonMax),lat=slice(bounds.latMin,bounds.latMax))\n",
    "                weightedMean = (areaSubset * np.asarray(weightsSubset)).sum('lat').sum('lon')\n",
    "            elif len(weights.dims)==1:\n",
    "                weightsSubset = weights.sel(lat=slice(bounds.latMin,bounds.latMax))\n",
    "                weightedMean = (areaSubset.mean('lon') * np.asarray(weightsSubset)).sum('lat')\n",
    "        except:\n",
    "            #try *not* using the weights from the files, which might need to be updated\n",
    "            useCosLat = True\n",
    "            print \"an exception!\", weights.shape\n",
    "            \n",
    "    if useCosLat:\n",
    "        weightsSubset = np.cos(np.deg2rad(areaSubset.lat))\n",
    "        weightedMean = (areaSubset.mean('lon') * np.asarray(weightsSubset)).sum('lat')\n",
    "        \n",
    "    weightTotal = weightsSubset.sum()\n",
    "    return weightedMean/np.double(weightTotal)\n",
    "\n",
    "def convertPrecipUnits(dataVsTime, startingFrom=''): # converts to mm/day                                                                                                                       \n",
    "    if startingFrom == 'm/s':\n",
    "        return dataVsTime * 1000.0 * 60.0 * 60.0 * 24.0\n",
    "    else: #default for CMIP5                                                                                                                           \n",
    "        return dataVsTime * 60.0*60.0*24.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOneFile(filename,field,bounds,weightFileName):\n",
    "    \n",
    "    oneEnsMem = xy.open_dataset(filename)\n",
    "        \n",
    "    #get weights from weighta file if exists:\n",
    "    try:\n",
    "        weights = xy.open_dataset(weightFileName)\n",
    "        weights = weights.areacella\n",
    "    except:\n",
    "        weights = None\n",
    "            \n",
    "    #we're not looking out past 2100, which a few models provide, and anyway it would cause indexing errors\n",
    "    if ('historical' not in filename) and ('CESMens' not in filename):\n",
    "        if ('IPSL-CM5A-LR' in filename or 'CSIRO-Mk3L-1-2' in filename): #len(oneEnsMem.time) >= 2262:\n",
    "            oneEnsMem = oneEnsMem.isel(time=slice(0,1500)) #just one century\n",
    "        oneEnsMem = oneEnsMem.sel(time=slice('2006-01-01','2099-12-31')) #a bit more exactly\n",
    "        #if(np.bool(oneEnsMem.time[-1] < np.datetime64('2099-11-30'))):\n",
    "            #print \"file doesn't go to end-of-century, only \", np.datetime_as_string(oneEnsMem.time[-1])\n",
    "    \n",
    "    timeSeries = getAreaAvg(oneEnsMem[field],bounds,weights).to_series() \n",
    "    if field == 'tas':\n",
    "        if oneEnsMem[field].units != 'K':\n",
    "            print filename\n",
    "            print oneEnsMem[field].units\n",
    "        if np.double(oneEnsMem[field].mean()) < 200.0:\n",
    "            print filename\n",
    "            print oneEnsMem[field].units\n",
    "    \n",
    "    if field == 'pr':\n",
    "        timeSeries = convertPrecipUnits(timeSeries)\n",
    "    \n",
    "    try:    \n",
    "        timeSeries.index = timeSeries.index.to_period(freq='M') \n",
    "    except:\n",
    "        print filename, \" has dates out of range\"\n",
    "    \n",
    "    return timeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOneModelAllFiles(dataDir,fileList,field,bounds,fileNameSplitter='_',fileNamePos=2,ensMemNumPos=4):\n",
    "    justFileName = fileList[0]\n",
    "    justModelName = str.split(justFileName,fileNameSplitter)[fileNamePos]\n",
    "    weightFileName = ''.join([weightPathAndPrefix,justModelName,weightSuffix]) #see constants.py\n",
    "    \n",
    "    ensMemList = []\n",
    "    for filename in fileList:\n",
    "        ensMemNum = str.split(filename,fileNameSplitter)[ensMemNumPos]\n",
    "        ensMemNum = str.split(ensMemNum,'i')[0]\n",
    "        ensMemNum = np.int(str.split(ensMemNum,'r')[1]) #the one or two digit integer between r and i in _r?i?p?_\n",
    "        if ensMemNum not in ensMemList:\n",
    "            ensMemList.append(ensMemNum)\n",
    "    \n",
    "    ensMemList.sort()\n",
    "    #print ensMemList\n",
    "    \n",
    "    def getOneEnsembleMember(ensMem):\n",
    "        firstFile = True\n",
    "        for filename in fileList:\n",
    "            ensMemNum = str.split(filename,fileNameSplitter)[ensMemNumPos]\n",
    "            ensMemNum = str.split(ensMemNum,'i')[0]\n",
    "            ensMemNum = np.int(str.split(ensMemNum,'r')[1]) #the one or two digit integer between r and i in _r?i?p?_\n",
    "\n",
    "            if ensMemNum == ensMem:\n",
    "                #print filename\n",
    "                onePartOfTimeSeries = getOneFile(''.join([dataDir,filename]),field,bounds,weightFileName)\n",
    "                onePartOfTimeSeries.name = ensMemNum\n",
    "                if firstFile:\n",
    "                    timeSeries = onePartOfTimeSeries\n",
    "                    firstFile = False\n",
    "                else:\n",
    "                    timeSeries = pd.concat([timeSeries,onePartOfTimeSeries],axis=0)\n",
    "\n",
    "        timeSeries.name = ''.join(['run',str(ensMem)])\n",
    "        #print timeSeries.name\n",
    "        #--------------\n",
    "        to_return = pd.DataFrame(timeSeries)\n",
    "    \n",
    "        #This last bit is necessary because at least one file has duplicate rows, probably from ncrcatting together\n",
    "        #more than one version of the same file. The values in the duplicate rows are not all identical.\n",
    "        to_return = to_return.reset_index().drop_duplicates(subset='time',keep='last').set_index('time')\n",
    "        to_return = to_return.sort_index()\n",
    "\n",
    "        return to_return.transpose()\n",
    "    \n",
    "    timeSeriesModel = pd.concat([getOneEnsembleMember(ensMem) for ensMem in ensMemList], axis=0)\n",
    "    timeSeriesModel.name = justModelName\n",
    "        \n",
    "    return timeSeriesModel.transpose()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do all regions, using pr or tas data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rcp85 pr Cali\n",
      "Cali pr rcp85 took 103.361913919\n",
      "rcp85 pr pnwMtnS\n",
      "pnwMtnS pr rcp85 took 20.3772301674\n",
      "rcp85 pr pnwMtn\n",
      "pnwMtn pr rcp85 took 17.946406126\n",
      "rcp85 pr BC\n",
      "BC pr rcp85 took 14.7816319466\n",
      "rcp85 pr Baja\n",
      "Baja pr rcp85 took 34.7705669403\n",
      "rcp85 pr pnwMtnN\n",
      "pnwMtnN pr rcp85 took 10.9103701115\n",
      "rcp85 pr pnwEast\n",
      "pnwEast pr rcp85 took 11.2850790024\n",
      "rcp85 pr global\n",
      "global pr rcp85 took 241.545455933\n",
      "rcp85 pr Alaska\n",
      "Alaska pr rcp85 took 12.4182679653\n",
      "rcp85 pr pnw\n",
      "pnw pr rcp85 took 11.3235609531\n",
      "rcp85 tas Cali\n",
      "Cali tas rcp85 took 311.839164972\n",
      "rcp85 tas pnwMtnS\n",
      "pnwMtnS tas rcp85 took 204.93326211\n",
      "rcp85 tas pnwMtn\n",
      "pnwMtn tas rcp85 took 168.833564043\n",
      "rcp85 tas BC\n",
      "BC tas rcp85 took 165.428349972\n",
      "rcp85 tas Baja\n",
      "Baja tas rcp85 took 197.306206942\n",
      "rcp85 tas pnwMtnN\n",
      "pnwMtnN tas rcp85 took 198.804570913\n",
      "rcp85 tas pnwEast\n",
      "pnwEast tas rcp85 took 187.008430958\n",
      "rcp85 tas global\n",
      "global tas rcp85 took 484.029780865\n",
      "rcp85 tas Alaska\n",
      "Alaska tas rcp85 took 196.504059076\n",
      "rcp85 tas pnw\n",
      "pnw tas rcp85 took 215.168066978\n",
      "rcp45 pr Cali\n",
      "Cali pr rcp45 took 55.9798469543\n",
      "rcp45 pr pnwMtnS\n",
      "pnwMtnS pr rcp45 took 20.4907310009\n",
      "rcp45 pr pnwMtn\n",
      "pnwMtn pr rcp45 took 17.998445034\n",
      "rcp45 pr BC\n",
      "BC pr rcp45 took 24.4284889698\n",
      "rcp45 pr Baja\n",
      "Baja pr rcp45 took 27.2163059711\n",
      "rcp45 pr pnwMtnN\n",
      "pnwMtnN pr rcp45 took 16.0274350643\n",
      "rcp45 pr pnwEast\n",
      "pnwEast pr rcp45 took 16.1163880825\n",
      "rcp45 pr global\n",
      "global pr rcp45 took 275.90759182\n",
      "rcp45 pr Alaska\n",
      "Alaska pr rcp45 took 17.4307050705\n",
      "rcp45 pr pnw\n",
      "pnw pr rcp45 took 16.0244419575\n",
      "rcp45 tas Cali\n",
      "Cali tas rcp45 took 300.546867847\n",
      "rcp45 tas pnwMtnS\n",
      "pnwMtnS tas rcp45 took 180.820466995\n",
      "rcp45 tas pnwMtn\n",
      "pnwMtn tas rcp45 took 163.343882084\n",
      "rcp45 tas BC\n",
      "BC tas rcp45 took 151.28371501\n",
      "rcp45 tas Baja\n",
      "Baja tas rcp45 took 180.863546133\n",
      "rcp45 tas pnwMtnN\n",
      "pnwMtnN tas rcp45 took 184.307137966\n",
      "rcp45 tas pnwEast\n",
      "pnwEast tas rcp45 took 214.543527126\n",
      "rcp45 tas global\n",
      "global tas rcp45 took 459.983239889\n",
      "rcp45 tas Alaska\n",
      "Alaska tas rcp45 took 196.328231096\n",
      "rcp45 tas pnw\n",
      "pnw tas rcp45 took 182.542088985\n",
      "rcp60 pr Cali\n",
      "Cali pr rcp60 took 39.4152958393\n",
      "rcp60 pr pnwMtnS\n",
      "pnwMtnS pr rcp60 took 7.33390903473\n",
      "rcp60 pr pnwMtn\n",
      "pnwMtn pr rcp60 took 7.57600188255\n",
      "rcp60 pr BC\n",
      "BC pr rcp60 took 5.29795479774\n",
      "rcp60 pr Baja\n",
      "Baja pr rcp60 took 11.3910651207\n",
      "rcp60 pr pnwMtnN\n",
      "pnwMtnN pr rcp60 took 3.82237505913\n",
      "rcp60 pr pnwEast\n",
      "pnwEast pr rcp60 took 3.79614210129\n",
      "rcp60 pr global\n",
      "global pr rcp60 took 125.6257689\n",
      "rcp60 pr Alaska\n",
      "Alaska pr rcp60 took 4.04031896591\n",
      "rcp60 pr pnw\n",
      "pnw pr rcp60 took 3.69797706604\n",
      "rcp60 tas Cali\n",
      "Cali tas rcp60 took 132.689485073\n",
      "rcp60 tas pnwMtnS\n",
      "pnwMtnS tas rcp60 took 96.498953104\n",
      "rcp60 tas pnwMtn\n",
      "pnwMtn tas rcp60 took 87.9576499462\n",
      "rcp60 tas BC\n",
      "BC tas rcp60 took 89.7355871201\n",
      "rcp60 tas Baja\n",
      "Baja tas rcp60 took 95.7843928337\n",
      "rcp60 tas pnwMtnN\n",
      "pnwMtnN tas rcp60 took 95.5020139217\n",
      "rcp60 tas pnwEast\n",
      "pnwEast tas rcp60 took 92.02267313\n",
      "rcp60 tas global\n",
      "global tas rcp60 took 221.509576082\n",
      "rcp60 tas Alaska\n",
      "Alaska tas rcp60 took 82.7043931484\n",
      "rcp60 tas pnw\n",
      "pnw tas rcp60 took 81.2393820286\n",
      "historical pr Cali\n",
      "Cali pr historical took 303.765911102\n",
      "historical pr pnwMtnS\n",
      "pnwMtnS pr historical took 64.2715070248\n",
      "historical pr pnwMtn\n",
      "pnwMtn pr historical took 74.9854609966\n",
      "historical pr BC\n",
      "BC pr historical took 73.179913044\n",
      "historical pr Baja\n",
      "Baja pr historical took 122.94149518\n",
      "historical pr pnwMtnN\n",
      "pnwMtnN pr historical took 36.1398670673\n",
      "historical pr pnwEast\n",
      "pnwEast pr historical took 35.7010769844\n",
      "historical pr global\n",
      "global pr historical took 671.14713192\n",
      "historical pr Alaska\n",
      "Alaska pr historical took 60.2016789913\n",
      "historical pr pnw\n",
      "pnw pr historical took 36.8517239094\n",
      "historical tas Cali\n",
      "Cali tas historical took 749.07850194\n",
      "historical tas pnwMtnS\n",
      "pnwMtnS tas historical took 480.070765018\n",
      "historical tas pnwMtn\n",
      "pnwMtn tas historical took 372.731185913\n",
      "historical tas BC\n",
      "BC tas historical took 420.0137012\n",
      "historical tas Baja\n",
      "Baja tas historical took 448.166105986\n",
      "historical tas pnwMtnN\n",
      "pnwMtnN tas historical took 473.088948965\n",
      "historical tas pnwEast\n",
      "pnwEast tas historical took 450.232477188\n",
      "historical tas global\n",
      "global tas historical took 1093.66727996\n",
      "historical tas Alaska\n",
      "Alaska tas historical took 449.735860109\n",
      "historical tas pnw\n",
      "pnw tas historical took 456.427564144\n",
      "rcp26 pr Cali\n",
      "Cali pr rcp26 took 32.0061061382\n",
      "rcp26 pr pnwMtnS\n",
      "pnwMtnS pr rcp26 took 9.94144892693\n",
      "rcp26 pr pnwMtn\n",
      "pnwMtn pr rcp26 took 10.296143055\n",
      "rcp26 pr BC\n",
      "BC pr rcp26 took 7.38064599037\n",
      "rcp26 pr Baja\n",
      "Baja pr rcp26 took 14.39686203\n",
      "rcp26 pr pnwMtnN\n",
      "pnwMtnN pr rcp26 took 5.74225282669\n",
      "rcp26 pr pnwEast\n",
      "pnwEast pr rcp26 took 5.50633096695\n",
      "rcp26 pr global\n",
      "global pr rcp26 took 155.889220953\n",
      "rcp26 pr Alaska\n",
      "Alaska pr rcp26 took 6.38548398018\n",
      "rcp26 pr pnw\n",
      "pnw pr rcp26 took 5.44248104095\n",
      "rcp26 tas Cali\n",
      "Cali tas rcp26 took 179.43426013\n",
      "rcp26 tas pnwMtnS\n",
      "pnwMtnS tas rcp26 took 117.762443781\n",
      "rcp26 tas pnwMtn\n",
      "pnwMtn tas rcp26 took 112.950677156\n",
      "rcp26 tas BC\n",
      "BC tas rcp26 took 113.51089406\n",
      "rcp26 tas Baja\n",
      "Baja tas rcp26 took 119.966599941\n",
      "rcp26 tas pnwMtnN\n",
      "pnwMtnN tas rcp26 took 121.615781069\n",
      "rcp26 tas pnwEast\n",
      "pnwEast tas rcp26 took 116.388781786\n",
      "rcp26 tas global\n",
      "global tas rcp26 took 261.568894863\n",
      "rcp26 tas Alaska\n",
      "Alaska tas rcp26 took 107.688690186\n",
      "rcp26 tas pnw\n",
      "pnw tas rcp26 took 107.234540224\n"
     ]
    }
   ],
   "source": [
    "scenariosCMIP = ['rcp85','rcp45','rcp60','historical','rcp26']\n",
    "fields = ['pr','tas']\n",
    "\n",
    "for scenario in scenariosCMIP:\n",
    "    for field in fields:\n",
    "        # edit dataDir to reflect your directory structure\n",
    "        dataDir = ''.join([dataDirCMIP,scenario,'/',field,'/'])\n",
    "        fileDict = getFileInfo(dataDir)\n",
    "        \n",
    "        # regionBounds is a dictionary defined as a global variable in constants.py\n",
    "        for regionKey in regionBounds:\n",
    "            print scenario, field, regionKey\n",
    "            time0 = time()\n",
    "            allData = pd.DataFrame()\n",
    "            allData = pd.concat([getOneModelAllFiles(dataDir,fileDict[model],field,regionBounds[regionKey]).transpose() for model in fileDict.keys()],axis=0,keys=fileDict.keys())\n",
    "            indexToUse = pd.MultiIndex.from_tuples(allData.transpose(),names=['model','run'])\n",
    "            allData.index = indexToUse\n",
    "            allData = allData.transpose()\n",
    "            if scenario == 'historical':\n",
    "                allData = allData['185001':'200512']\n",
    "            outFile = ''.join(['timeSeries/timeSeries_',field,'_',regionKey,'_Monthly_',scenario,'.csv'])\n",
    "            allData.to_csv(outFile)\n",
    "            time1 = time()\n",
    "            print ' '.join([regionKey,field,scenario,'took',str(time1-time0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
