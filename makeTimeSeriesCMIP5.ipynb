{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the definitive version for producing CMIP5 time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xy\n",
    "import string\n",
    "from copy import deepcopy\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "from constants import * #<= my defined global variables\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFileInfo(dataDir,fileNameSplitter='_',fileNamePos=2):\n",
    "    def justDataFiles(path=None):\n",
    "        for f in os.listdir(path):\n",
    "            if ('p1_21' not in f) and ('p1_22' not in f) and ('.nc' in f):\n",
    "                yield f\n",
    "            \n",
    "    files = [x for x in justDataFiles(dataDir)]  \n",
    "    files.sort()\n",
    "    \n",
    "    #make a list of the model names in this file list\n",
    "    modelNames = []\n",
    "    for oneFile in files:\n",
    "        justFileName = str.split(oneFile,'/')[-1]\n",
    "        #print justFileName\n",
    "        justEnsMemNum = str.split(justFileName,fileNameSplitter)[fileNamePos]\n",
    "        #print justEnsMemNum\n",
    "        modelNames.append(justEnsMemNum)\n",
    "    modelNames = list(set(modelNames))\n",
    "\n",
    "    #make a dictionary of all the files that go with each model\n",
    "    keyvaluepairs = []\n",
    "    for model in modelNames:\n",
    "        uniqueModelName = ''.join([model,fileNameSplitter])\n",
    "        oneModelFileList = []\n",
    "        for oneFile in files:\n",
    "            if uniqueModelName in oneFile:\n",
    "                oneModelFileList.append(oneFile)\n",
    "        tupleOfKeyValue = (model,oneModelFileList)\n",
    "        keyvaluepairs.append(tupleOfKeyValue)\n",
    "\n",
    "    fileDict = dict(keyvaluepairs)\n",
    "    \n",
    "    return fileDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getAreaAvg(data,bounds,weights,landFrac): #,t,weights):\n",
    "\n",
    "    weightedMean = 0.0\n",
    "    weightTotal = 0.0\n",
    "    \n",
    "    areaSubset = data.sel(lon=slice(bounds.lonMin,bounds.lonMax),lat=slice(bounds.latMin,bounds.latMax)) #.isel(time=t)\n",
    "    if landFrac:\n",
    "        landFrac = landFrac.sel(lon=slice(bounds.lonMin,bounds.lonMax),lat=slice(bounds.latMin,bounds.latMax))\n",
    "        areaSubset = areaSubset.where(landFrac>0.5)\n",
    "        \n",
    "    useCosLat = False\n",
    "    if weights is None:\n",
    "        useCosLat = True\n",
    "    else:\n",
    "        try:\n",
    "            if len(weights.dims)==2:\n",
    "                weightsSubset = weights.sel(lon=slice(bounds.lonMin,bounds.lonMax),lat=slice(bounds.latMin,bounds.latMax))\n",
    "                weightedMean = (areaSubset * np.asarray(weightsSubset)).sum('lat').sum('lon')\n",
    "            elif len(weights.dims)==1:\n",
    "                weightsSubset = weights.sel(lat=slice(bounds.latMin,bounds.latMax))\n",
    "                weightedMean = (areaSubset.mean('lon') * np.asarray(weightsSubset)).sum('lat')\n",
    "        except:\n",
    "            #try *not* using the weights from the files, which might need to be updated\n",
    "            useCosLat = True\n",
    "            print \"an exception!\", weights.shape\n",
    "            \n",
    "    if useCosLat:\n",
    "        weightsSubset = np.cos(np.deg2rad(areaSubset.lat))\n",
    "        weightedMean = (areaSubset.mean('lon') * np.asarray(weightsSubset)).sum('lat')\n",
    "        \n",
    "    weightTotal = weightsSubset.sum()\n",
    "    return weightedMean/np.double(weightTotal)\n",
    "\n",
    "def convertPrecipUnits(dataVsTime, startingFrom=''): # converts to mm/day                                                                                                                       \n",
    "    if startingFrom == 'm/s':\n",
    "        return dataVsTime * 1000.0 * 60.0 * 60.0 * 24.0\n",
    "    else: #default for CMIP5                                                                                                                           \n",
    "        return dataVsTime * 60.0*60.0*24.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getOneFile(filename,field,bounds,weightFileName,landFracFileName):\n",
    "    \n",
    "    oneEnsMem = xy.open_dataset(filename)\n",
    "        \n",
    "    #get weights from weighta file if exists:\n",
    "    try:\n",
    "        weights = xy.open_dataset(weightFileName)\n",
    "        weights = weights.areacella\n",
    "    except:\n",
    "        weights = None\n",
    "        \n",
    "    #get land fraction data if exists:\n",
    "    try:\n",
    "        landFrac = xy.open_dataset(landFracFileName)\n",
    "        landFrac = landFrac.sftlf\n",
    "    except:\n",
    "        landFrac = None\n",
    "            \n",
    "    #we're not looking out past 2100, which a few models provide, and anyway it would cause indexing errors\n",
    "    if ('historical' not in filename) and ('CESMens' not in filename):\n",
    "        if ('IPSL-CM5A-LR' in filename or 'CSIRO-Mk3L-1-2' in filename): #len(oneEnsMem.time) >= 2262:\n",
    "            oneEnsMem = oneEnsMem.isel(time=slice(0,1140)) #just until 2100-12 century\n",
    "            oneEnsMem['time'] = pd.date_range('2006-01-01',periods=1140,freq='MS')\n",
    "        oneEnsMem = oneEnsMem.sel(time=slice('2006-01-01','2099-12-31')) #a bit more exactly\n",
    "        #if(np.bool(oneEnsMem.time[-1] < np.datetime64('2099-11-30'))):\n",
    "            #print \"file doesn't go to end-of-century, only \", np.datetime_as_string(oneEnsMem.time[-1])\n",
    "    \n",
    "    timeSeries = getAreaAvg(oneEnsMem[field],bounds,weights,landFrac).to_series() \n",
    "    if field == 'tas':\n",
    "        if oneEnsMem[field].units != 'K':\n",
    "            print filename\n",
    "            print oneEnsMem[field].units\n",
    "        if np.double(oneEnsMem[field].mean()) < 200.0:\n",
    "            print filename\n",
    "            print oneEnsMem[field].units\n",
    "    \n",
    "    if field == 'pr':\n",
    "        timeSeries = convertPrecipUnits(timeSeries)\n",
    "    \n",
    "    try:    \n",
    "        timeSeries.index = timeSeries.index.to_period(freq='M') \n",
    "    except:\n",
    "        print filename, \" has dates out of range\"\n",
    "        print timeSeries.index\n",
    "    \n",
    "    return timeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getOneModelAllFiles(dataDir,fileList,field,bounds,fileNameSplitter='_',fileNamePos=2,ensMemNumPos=4):\n",
    "    justFileName = fileList[0]\n",
    "    justModelName = str.split(justFileName,fileNameSplitter)[fileNamePos]\n",
    "    weightFileName = ''.join([weightPathAndPrefix,justModelName,weightSuffix]) #see constants.py\n",
    "    try:\n",
    "        landFracFileName = landFracFiles[justModelName][0]\n",
    "    except:\n",
    "        landFracFileName = None\n",
    "        print \"no land frac file for \", justModelName\n",
    "    \n",
    "    ensMemList = []\n",
    "    for filename in fileList:\n",
    "        ensMemNum = str.split(filename,fileNameSplitter)[ensMemNumPos]\n",
    "        ensMemNum = str.split(ensMemNum,'i')[0]\n",
    "        ensMemNum = np.int(str.split(ensMemNum,'r')[1]) #the one or two digit integer between r and i in _r?i?p?_\n",
    "        if ensMemNum not in ensMemList:\n",
    "            ensMemList.append(ensMemNum)\n",
    "    \n",
    "    ensMemList.sort()\n",
    "    #print ensMemList\n",
    "    \n",
    "    def getOneEnsembleMember(ensMem):\n",
    "        firstFile = True\n",
    "        for filename in fileList:\n",
    "            ensMemNum = str.split(filename,fileNameSplitter)[ensMemNumPos]\n",
    "            ensMemNum = str.split(ensMemNum,'i')[0]\n",
    "            ensMemNum = np.int(str.split(ensMemNum,'r')[1]) #the one or two digit integer between r and i in _r?i?p?_\n",
    "\n",
    "            if ensMemNum == ensMem:\n",
    "                #print filename\n",
    "                onePartOfTimeSeries = getOneFile(''.join([dataDir,filename]),field,bounds,weightFileName,landFracFileName)\n",
    "                onePartOfTimeSeries.name = ensMemNum\n",
    "                if firstFile:\n",
    "                    timeSeries = onePartOfTimeSeries\n",
    "                    firstFile = False\n",
    "                else:\n",
    "                    timeSeries = pd.concat([timeSeries,onePartOfTimeSeries],axis=0)\n",
    "\n",
    "        timeSeries.name = ''.join(['run',str(ensMem)])\n",
    "        #print timeSeries.name\n",
    "        #--------------\n",
    "        to_return = pd.DataFrame(timeSeries)\n",
    "    \n",
    "        #This last bit is necessary because at least one file has duplicate rows, probably from ncrcatting together\n",
    "        #more than one version of the same file. The values in the duplicate rows are not all identical.\n",
    "        to_return = to_return.reset_index().drop_duplicates(subset='time',keep='last').set_index('time')\n",
    "        to_return = to_return.sort_index()\n",
    "\n",
    "        return to_return.transpose()\n",
    "    \n",
    "    timeSeriesModel = pd.concat([getOneEnsembleMember(ensMem) for ensMem in ensMemList], axis=0)\n",
    "    timeSeriesModel.name = justModelName\n",
    "        \n",
    "    return timeSeriesModel.transpose()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do all regions, using pr or tas data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rcp85 pr BC\n",
      "BC pr rcp85 took 35.3653481007\n",
      "rcp85 pr global\n",
      "global pr rcp85 took 216.50000596\n",
      "rcp85 pr Alaska\n",
      "Alaska pr rcp85 took 14.0571320057\n",
      "rcp85 pr pnw\n",
      "pnw pr rcp85 took 11.3828210831\n",
      "rcp85 pr Cali\n",
      "Cali pr rcp85 took 22.1038930416\n",
      "rcp85 pr Baja\n",
      "Baja pr rcp85 took 21.4893670082\n",
      "rcp85 tas BC\n",
      "BC tas rcp85 took 280.571213961\n",
      "rcp85 tas global\n",
      "global tas rcp85 took 379.598862886\n",
      "rcp85 tas Alaska\n",
      "Alaska tas rcp85 took 170.876077175\n",
      "rcp85 tas pnw\n",
      "pnw tas rcp85 took 164.165060043\n",
      "rcp85 tas Cali\n",
      "Cali tas rcp85 took 161.773633957\n",
      "rcp85 tas Baja\n",
      "Baja tas rcp85 took 168.911726952\n",
      "rcp45 pr BC\n",
      "BC pr rcp45 took 215.067417145\n",
      "rcp45 pr global\n",
      "global pr rcp45 took 297.32111907\n",
      "rcp45 pr Alaska\n",
      "Alaska pr rcp45 took 24.949409008\n",
      "rcp45 pr pnw\n",
      "pnw pr rcp45 took 49.7334051132\n",
      "rcp45 pr Cali\n",
      "Cali pr rcp45 took 50.1931569576\n",
      "rcp45 pr Baja\n",
      "Baja pr rcp45 took 73.2081429958\n",
      "rcp45 tas BC\n",
      "BC tas rcp45 took 438.459601879\n",
      "rcp45 tas global\n",
      "global tas rcp45 took 415.466571808\n",
      "rcp45 tas Alaska\n",
      "Alaska tas rcp45 took 184.762254953\n",
      "rcp45 tas pnw\n",
      "pnw tas rcp45 took 171.020033121\n",
      "rcp45 tas Cali\n",
      "Cali tas rcp45 took 188.05385685\n",
      "rcp45 tas Baja\n",
      "Baja tas rcp45 took 191.990807056\n",
      "rcp60 pr BC\n",
      "BC pr rcp60 took 99.8120360374\n",
      "rcp60 pr global\n",
      "global pr rcp60 took 108.399734974\n",
      "rcp60 pr Alaska\n",
      "Alaska pr rcp60 took 8.86299109459\n",
      "rcp60 pr pnw\n",
      "pnw pr rcp60 took 4.02848100662\n",
      "rcp60 pr Cali\n",
      "Cali pr rcp60 took 3.9706029892\n",
      "rcp60 pr Baja\n",
      "Baja pr rcp60 took 3.72049379349\n",
      "rcp60 tas BC\n",
      "BC tas rcp60 took 175.114710808\n",
      "rcp60 tas global\n",
      "global tas rcp60 took 225.118155956\n",
      "rcp60 tas Alaska\n",
      "Alaska tas rcp60 took 94.1363940239\n",
      "rcp60 tas pnw\n",
      "pnw tas rcp60 took 79.215555191\n",
      "rcp60 tas Cali\n",
      "Cali tas rcp60 took 100.078251123\n",
      "rcp60 tas Baja\n",
      "Baja tas rcp60 took 74.2331647873\n",
      "historical pr BC\n",
      "BC pr historical took 516.078696966\n",
      "historical pr global\n",
      "global pr historical took 691.472245932\n",
      "historical pr Alaska\n",
      "Alaska pr historical took 146.671538115\n",
      "historical pr pnw\n",
      "pnw pr historical took 126.980565071\n",
      "historical pr Cali\n",
      "Cali pr historical took 128.556891203\n",
      "historical pr Baja\n",
      "Baja pr historical took 130.091117144\n",
      "historical tas BC\n",
      "BC tas historical took 1100.78480983\n",
      "historical tas global\n",
      "global tas historical took 1213.01612997\n",
      "historical tas Alaska\n",
      "Alaska tas historical took 772.386815786\n",
      "historical tas pnw\n",
      "pnw tas historical took 566.694281816\n",
      "historical tas Cali\n",
      "Cali tas historical took 490.329511881\n",
      "historical tas Baja\n",
      "Baja tas historical took 503.729640961\n",
      "rcp26 pr BC\n",
      "BC pr rcp26 took 183.778109074\n",
      "rcp26 pr global\n",
      "global pr rcp26 took 130.187326193\n",
      "rcp26 pr Alaska\n",
      "Alaska pr rcp26 took 5.40169095993\n",
      "rcp26 pr pnw\n",
      "pnw pr rcp26 took 5.32235503197\n",
      "rcp26 pr Cali\n",
      "Cali pr rcp26 took 5.06412816048\n",
      "rcp26 pr Baja\n",
      "Baja pr rcp26 took 5.20730686188\n",
      "rcp26 tas BC\n",
      "BC tas rcp26 took 285.548521042\n",
      "rcp26 tas global\n",
      "global tas rcp26 took 263.282813072\n",
      "rcp26 tas Alaska\n",
      "Alaska tas rcp26 took 101.823193789\n",
      "rcp26 tas pnw\n",
      "pnw tas rcp26 took 95.7368500233\n",
      "rcp26 tas Cali\n",
      "Cali tas rcp26 took 90.7257809639\n",
      "rcp26 tas Baja\n",
      "Baja tas rcp26 took 97.5577809811\n"
     ]
    }
   ],
   "source": [
    "scenariosCMIP = ['rcp85','rcp45','rcp60','historical','rcp26']\n",
    "fields = ['pr','tas']\n",
    "\n",
    "landFracFiles = getFileInfo(landFracPath)\n",
    "\n",
    "for scenario in scenariosCMIP:\n",
    "    for field in fields:\n",
    "        # edit dataDir to reflect your directory structure\n",
    "        dataDir = ''.join([dataDirCMIP,scenario,'/',field,'/'])\n",
    "        fileDict = getFileInfo(dataDir)\n",
    "        # leave if off if there is no land-sea mask:\n",
    "        for key in fileDict.keys():\n",
    "            if key not in landFracFiles.keys():\n",
    "                del fileDict[key]\n",
    "        \n",
    "        # regionBounds is a dictionary defined as a global variable in constants.py\n",
    "        for regionKey in regionBounds:\n",
    "            print scenario, field, regionKey\n",
    "            time0 = time()\n",
    "            allData = pd.DataFrame()\n",
    "            allData = pd.concat([getOneModelAllFiles(dataDir,fileDict[model],field,regionBounds[regionKey]).transpose() for model in fileDict.keys()],axis=0,keys=fileDict.keys())\n",
    "            indexToUse = pd.MultiIndex.from_tuples(allData.transpose(),names=['model','run'])\n",
    "            allData.index = indexToUse\n",
    "            allData = allData.transpose()\n",
    "            if scenario == 'historical':\n",
    "                allData = allData['185001':'200512']\n",
    "            outFile = ''.join(['timeSeries/timeSeries_',field,'_',regionKey,'_Monthly_',scenario,'.csv'])\n",
    "            allData.to_csv(outFile)\n",
    "            time1 = time()\n",
    "            print ' '.join([regionKey,field,scenario,'took',str(time1-time0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
