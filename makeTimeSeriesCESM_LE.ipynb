{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the definitive version for producing CESM LE timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xy\n",
    "import string\n",
    "from copy import deepcopy\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "from constants import * #<= my defined global variables\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFileInfo(dataDir,fileNameSplitter='_',fileNamePos=2):\n",
    "    def justDataFiles(path=None):\n",
    "        for f in os.listdir(path):\n",
    "            if ('r1i1p1_21' not in f) and ('r1i1p1_22' not in f) and ('.nc' in f) and \\\n",
    "                ('.106.' not in f) and ('.107.' not in f) :\n",
    "                yield f\n",
    "            \n",
    "    files = [x for x in justDataFiles(dataDir)]  \n",
    "    files.sort()\n",
    "\n",
    "    #make a list of the model names in this file list\n",
    "    modelNames = []\n",
    "    for oneFile in files:\n",
    "        justFileName = str.split(oneFile,'/')[-1]\n",
    "        #print justFileName\n",
    "        justEnsMemNum = str.split(justFileName,fileNameSplitter)[fileNamePos]\n",
    "        #print justEnsMemNum\n",
    "        modelNames.append(justEnsMemNum)\n",
    "    modelNames = list(set(modelNames))\n",
    "\n",
    "    #make a dictionary of all the files that go with each model\n",
    "    keyvaluepairs = []\n",
    "    for model in modelNames:\n",
    "        #uniqueModelName = ''.join([model,fileNameSplitter])\n",
    "        oneModelFileList = []\n",
    "        for oneFile in files:\n",
    "            justFileName = str.split(oneFile,'/')[-1]\n",
    "            justEnsMemNum = str.split(justFileName,fileNameSplitter)[fileNamePos]\n",
    "            if model == justEnsMemNum:\n",
    "            #if uniqueModelName in oneFile:\n",
    "                oneModelFileList.append(oneFile)\n",
    "        tupleOfKeyValue = (model,oneModelFileList)\n",
    "        keyvaluepairs.append(tupleOfKeyValue)\n",
    "\n",
    "    fileDict = dict(keyvaluepairs)\n",
    "    \n",
    "    return fileDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myDateTimeIndex1 = []\n",
    "endDay = [31,28,31,30,31,30,31,31,30,31,30,31]\n",
    "endMonth=12\n",
    "for year in np.arange(1850,2101,1):\n",
    "    for month in np.arange(1,endMonth+1,1):\n",
    "        day=1\n",
    "        oneDateTime = pd.datetime(year,month,day)\n",
    "        myDateTimeIndex1.append(oneDateTime)            \n",
    "myDateTimeIndex1 = pd.DatetimeIndex(myDateTimeIndex1)\n",
    "\n",
    "myDateTimeIndex2to40 = []\n",
    "for year in np.arange(1920,2101,1):\n",
    "    for month in np.arange(1,endMonth+1,1):\n",
    "        day=1\n",
    "        oneDateTime = pd.datetime(year,month,day)\n",
    "        myDateTimeIndex2to40.append(oneDateTime)            \n",
    "myDateTimeIndex2to40 = pd.DatetimeIndex(myDateTimeIndex2to40)\n",
    "\n",
    "myDateTimeIndexRCP45 = []\n",
    "for year in np.arange(1920,2081,1):\n",
    "    for month in np.arange(1,endMonth+1,1):\n",
    "        day=1\n",
    "        oneDateTime = pd.datetime(year,month,day)\n",
    "        myDateTimeIndexRCP45.append(oneDateTime)            \n",
    "myDateTimeIndexRCP45 = pd.DatetimeIndex(myDateTimeIndexRCP45)\n",
    "\n",
    "myDateTimeIndexRCP45_1 = []\n",
    "for year in np.arange(1850,2081,1):\n",
    "    for month in np.arange(1,endMonth+1,1):\n",
    "        day=1\n",
    "        oneDateTime = pd.datetime(year,month,day)\n",
    "        myDateTimeIndexRCP45_1.append(oneDateTime)            \n",
    "myDateTimeIndexRCP45_1 = pd.DatetimeIndex(myDateTimeIndexRCP45_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fix_my_data(ds):\n",
    "    return ds[field].squeeze().to_dataset(name=field)\n",
    "\n",
    "def readDataCESMLE(fileName,field):\n",
    "    dataOneEnsMem = xy.open_mfdataset(fileName,preprocess=fix_my_data,decode_times=False) \n",
    "    isFirstOne = False\n",
    "    for oneFile in fileName:\n",
    "        if '1850' in oneFile:\n",
    "            isFirstOne = True\n",
    "    if isFirstOne:\n",
    "        if 'rcp45' in fileName[0]:\n",
    "            myDateTimeIndex = myDateTimeIndexRCP45_1\n",
    "        else:    \n",
    "            myDateTimeIndex = myDateTimeIndex1\n",
    "    elif 'rcp45' in fileName[0]:\n",
    "        myDateTimeIndex = myDateTimeIndexRCP45\n",
    "    else:\n",
    "        myDateTimeIndex = myDateTimeIndex2to40\n",
    "    lon = deepcopy(dataOneEnsMem['lon'])\n",
    "    lat = deepcopy(dataOneEnsMem['lat'])\n",
    "    myData = xy.DataArray(deepcopy(dataOneEnsMem[field].squeeze()), coords=[myDateTimeIndex,lat,lon],dims=['time','lat','lon'])\n",
    "    dataOneEnsMem.close()\n",
    "    \n",
    "    return myData\n",
    "\n",
    "#get CESM weights, just once\n",
    "temp = xy.open_dataset(weightFileCESM) #filename in constants.py\n",
    "weightsCESM = deepcopy(temp['gw'])\n",
    "temp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAreaAvg(data,bounds,weights,landFrac): \n",
    "\n",
    "    weightedMean = 0.0\n",
    "    weightTotal = 0.0\n",
    "    \n",
    "    areaSubset = data.sel(lon=slice(bounds.lonMin,bounds.lonMax),lat=slice(bounds.latMin,bounds.latMax)) \n",
    "    landFrac = landFrac.sel(lon=slice(bounds.lonMin,bounds.lonMax),lat=slice(bounds.latMin,bounds.latMax))\n",
    "    areaSubset = areaSubset.where(landFrac>0.5)\n",
    "    \n",
    "    useCosLat = False\n",
    "    try:\n",
    "        if len(weights.dims)==2:\n",
    "            weightsSubset = weights.sel(lon=slice(bounds.lonMin,bounds.lonMax),lat=slice(bounds.latMin,bounds.latMax))\n",
    "            weightedMean = (areaSubset * weightsSubset).sum('lat').sum('lon')\n",
    "        elif len(weights.dims)==1:\n",
    "            weightsSubset = weights.sel(lat=slice(bounds.latMin,bounds.latMax))\n",
    "            weightedMean = (areaSubset.mean('lon') * np.asarray(weightsSubset)).sum('lat')\n",
    "    except:\n",
    "        #try *not* using the weights from the files, which might need to be updated\n",
    "        useCosLat = True\n",
    "        print \"an exception!\"\n",
    "             \n",
    "    if useCosLat:\n",
    "        weightsSubset = np.cos(np.deg2rad(areaSubset.lat))\n",
    "        weightedMean = (areaSubset.mean('lon') * np.asarray(weightsSubset)).sum('lat')\n",
    "        \n",
    "    weightTotal = weightsSubset.sum()\n",
    "    return weightedMean/np.double(weightTotal)\n",
    "\n",
    "def convertPrecipUnits(dataVsTime, startingFrom=''): # converts to mm/day                                                                                                                       \n",
    "    if startingFrom == 'm/s':\n",
    "        return dataVsTime * 1000.0 * 60.0 * 60.0 * 24.0\n",
    "    else: #default for CMIP5                                                                                                                           \n",
    "        return dataVsTime * 60.0*60.0*24.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getOneFile(filename,field,bounds,frequency='monthly'):\n",
    "    \n",
    "    oneEnsMem = readDataCESMLE(filename,field)\n",
    "    \n",
    "    landFracFileName = 'b.e11.B20TRC5CNBDRD.f09_g16.'+filename[0].split('.')[4]+'.cam.h0.LANDFRAC.'+filename[0].split('.')[8]+'.nc'\n",
    "    lf = xy.open_dataset(landFracCESM+landFracFileName)\n",
    "    landFrac = deepcopy(lf['LANDFRAC'].isel(time=0))\n",
    "    landFrac.drop('time')\n",
    "    lf.close()\n",
    "        \n",
    "    timeSeries = getAreaAvg(oneEnsMem,bounds,weightsCESM,landFrac).to_series() \n",
    "    if field == 'PRECT':\n",
    "        timeSeries = convertPrecipUnits(timeSeries,'m/s')\n",
    "        \n",
    "    timeSeries.index = timeSeries.index.to_period(freq='M') \n",
    "    \n",
    "    return timeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getOneModelAllFiles(dataDir,fileList,field,bounds,fileNameSplitter='_',fileNamePos=2):\n",
    "    justFileName = str.split(fileList[0],'/')[-1]\n",
    "    justModelName = str.split(justFileName,fileNameSplitter)[fileNamePos]\n",
    "    timeSeries = getOneFile([dataDir+filename for filename in fileList],field,bounds)\n",
    "    \n",
    "    timeSeries.name = justModelName\n",
    "    to_return = pd.DataFrame(timeSeries)\n",
    "    \n",
    "    #This last bit is necessary because at least one file has duplicate rows, probably from ncrcatting together\n",
    "    #more than one version of the same file. The values in the duplicate rows are not all identical.\n",
    "    to_return = to_return.reset_index().drop_duplicates(subset='time',keep='last').set_index('time')\n",
    "    to_return = to_return.sort_index()\n",
    "    #--------------\n",
    "    return to_return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do all regions, using PRECT or TS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BC PRECT rcp85 took 246.974248171\n",
      "global PRECT rcp85 took 306.685336113\n",
      "Alaska PRECT rcp85 took 243.009891987\n",
      "pnw PRECT rcp85 took 232.571203947\n",
      "Cali PRECT rcp85 took 243.01224494\n",
      "Baja PRECT rcp85 took 229.88039279\n",
      "BC TS rcp85 took 230.159853935\n",
      "global TS rcp85 took 320.584588051\n",
      "Alaska TS rcp85 took 274.099545002\n",
      "pnw TS rcp85 took 254.131719112\n",
      "Cali TS rcp85 took 308.839993954\n",
      "Baja TS rcp85 took 281.270713091\n"
     ]
    }
   ],
   "source": [
    "fileNameSplitter = '.'\n",
    "fileNamePos = 4\n",
    "fields = ['PRECT','TS']\n",
    "\n",
    "for scenario in scenariosLE:\n",
    "    for field in fields:\n",
    "        #edit 'dataDir' to reflect your directory structure:\n",
    "        dataDir = ''.join([dataDirCESM,scenario,'/monthly/',field,'/']) \n",
    "        fileDict = getFileInfo(dataDir,fileNameSplitter,fileNamePos)\n",
    "        \n",
    "        # regionBounds is a dictionary defined as a global variable in constants.py\n",
    "        for regionKey in regionBounds:\n",
    "            time0 = time()\n",
    "            allData = pd.DataFrame()\n",
    "            allData = pd.concat([getOneModelAllFiles(dataDir,fileDict[model],field,regionBounds[regionKey],fileNameSplitter,fileNamePos) for model in fileDict.keys()],axis=1)            \n",
    "            outFile = ''.join(['timeSeries/timeSeries_',field,'_',regionKey,'_Monthly_cesmLE_',scenario,'.csv'])\n",
    "            allData.to_csv(outFile)\n",
    "            time1 = time()\n",
    "            print ' '.join([regionKey,field,scenario,'took',str(time1-time0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output a copy of allData to inspect one:\n",
    "allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
